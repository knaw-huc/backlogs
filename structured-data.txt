//current max task number: T158

# New
- [ ] T156: Do not make all collections editable by default.
        - See: https://github.com/HuygensING/timbuctoo/blob/configure-collection-editability/documentation/design/collection-editability.adoc
- [ ] T155: Updaten van collectie metadata geeft geen goede foutmelding als de collectie niet bestaat.
- [ ] T153: `timbuctoo gooit een 500 als de query niet goed parsed en zou de parse error en een 400 moeten teruggeven`
	- Gebeurd bij bewerken dataset metadata (Lodewijk heeft de query)
- [ ] T154: Indexering duurt lang / gebruikers zien niet wanneer deze klaar is
	- De Date range facets werken niet goed. Wanneer je bijvoorbeeld in 2TBI-dataset-personen (https://anansi.clariah.nl/details/u74ccc032adf8422d7ea92df96cd4783f0543db3b__tbi/schema_PersonList) filtert op een bepaalde range in sterfjaar, komen de resultaten niet altijd overeen met het ingestelde filter.
	-  Update: na lang wachten (ca 12 uur) blijken de facets toch soms te zijn geïmplementeerd. Probleem blijft dat er geen feedback is over het proces, en dat bij de date ranges de resultaten niet altijd overeenkomen met het ingestelde filter en dat de getoonde aantallen in de filters vaak een veelvoud (2x / 3x) betreft van het aantal relevante resultaten.
- [X] T147: Investigate why 2TBI dataset.nq upload on September 11th didn't get all data into anansi.
- [ ] T144: Json-LD upload fails through the Timbuctoo-GUI (works with REST)
- [ ] T141: DatabaseGetter.partialKey() only works with key.startsWith()
	It cuts of the iterator at the first non-matching value.
	This currently slows down the retrieval of the resourcesync changes.
- [X] T140: Stardog-server @Golden Agents: size limit
- [ ] T148: research how much time is needed for upgrade to Java 11 [cf. T133]
- [ ] T149: research into dependencies in Timbuctoo
- [ ] T150: NEWW VRE - add new attribute/facet [??tbd]'Status' (value: 'Private' OR 'Public') to Publications and Receptions
- [ ] T152: how should outgoing links (i.e. e.g. value=http://example.org) be configured?

# Production blockers
  
# Production bugs
  - [ ] T158: Het opvragen van datasets met iets anders dat READ rechten geeft te weinig datasets terug.
	- Geef me datasets terug waar ik write of admin rechten op heb geven te weinig datasetes terug.
  - [ ] T157: Resourcesync update fails because there is no resourcesync information available.
	- Create a decent error message for resourcesync update when not import information is available.
	- Make sure the resourcesync information is stored to disc, when a data set is created with resourcesync.
	- Lodewijk created a new dataset and that got the resourcesync information.
	- Could it be that the problem could arises after a resourcesync update?
  - [ ] T120: Detail view van importstatus heeft een bug
        - In eerste instantie 8 importers, later 2 met exact dezelfde informatie.
  - [.] T121: Importer heeft een bug. Ik was twee datasets tegelijk aan het uploaden en paste toen de naam van de eerste dataset aan. Dan zie je twee imports lopen (van beide datasets 1) toen de tweede import klaar was ging de 2e log van de eerste dataset ook al importeren. Voordat de eerste log dus klaar was. 
  - [>T096] T030: Database sluit na upload en mapping
  - [>T097] T029: Schema geeft meer properties in metadata terug, dan die beschikbaar zijn (owl:sameAs bioport person, het ophalen van unknown via sameAs)
  - [.] T134: New import Node Goat does not import all information, look into the resourcesync docs if their current changelist is valid. 
          If it is valid make sure it imports all data.

  - [ ] T139: Handle does not work on data.huygens and problably has the same problems on anansi and golden agents
nl.knaw.huygens.persistence.PersistenceException: HandleException (INTERNAL_ERROR) Error setting up session
	at nl.knaw.huygens.persistence.HandleManager.persistURL(HandleManager.java:180)
	at nl.knaw.huygens.timbuctoo.handle.HandleAdder.actualExecution(HandleAdder.java:47)
	at com.kjetland.dropwizard.activemq.ActiveMQReceiverHandler.processMessage(ActiveMQReceiverHandler.java:122)
	at com.kjetland.dropwizard.activemq.ActiveMQReceiverHandler.runReceiveLoop(ActiveMQReceiverHandler.java:270)
	at com.kjetland.dropwizard.activemq.ActiveMQReceiverHandler.run(ActiveMQReceiverHandler.java:203)
	at java.lang.Thread.run(Thread.java:748)
Caused by: net.handle.hdllib.HandleException: Error setting up session
	at net.handle.hdllib.HandleResolver.sendRequestToServerByProtocol(HandleResolver.java:1889)
	at net.handle.hdllib.HandleResolver.sendRequestToServerByProtocol(HandleResolver.java:1818)
	at net.handle.hdllib.HandleResolver.sendRequestToServerInSiteByProtocol(HandleResolver.java:1649)
	at net.handle.hdllib.HandleResolver.sendRequestToSite(HandleResolver.java:1627)
	at net.handle.hdllib.HappyEyeballsResolver.sendRequestToSiteViaProtocol(HappyEyeballsResolver.java:205)
	at net.handle.hdllib.HappyEyeballsResolver.sendRequestToSites(HappyEyeballsResolver.java:173)
	at net.handle.hdllib.HappyEyeballsResolver.sendRequestAndSetResponseOrPublicException(HappyEyeballsResolver.java:151)
	at net.handle.hdllib.HappyEyeballsResolver.run(HappyEyeballsResolver.java:90)
	at net.handle.hdllib.HandleResolver.sendRequestToService(HandleResolver.java:1165)
	at net.handle.hdllib.HandleResolver.processRequestGlobally(HandleResolver.java:618)
	at net.handle.hdllib.HandleResolver.processRequest(HandleResolver.java:590)
	at net.handle.hdllib.HandleResolver.processRequest(HandleResolver.java:603)
	at nl.knaw.huygens.persistence.HandleManager.persistURL(HandleManager.java:177)
	... 5 common frames omitted
Caused by: java.security.NoSuchAlgorithmException: Unsupported secret key algorithm: AES
	at com.sun.crypto.provider.DHKeyAgreement.engineGenerateSecret(DHKeyAgreement.java:387)
	at javax.crypto.KeyAgreement.generateSecret(KeyAgreement.java:648)
	at net.handle.security.provider.GenericProvider.getKeyFromDH(GenericProvider.java:207)
	at net.handle.hdllib.HandleResolver.setupSessionWithServer(HandleResolver.java:2207)
	at net.handle.hdllib.HandleResolver.setupSessionWithServer(HandleResolver.java:2062)
	at net.handle.hdllib.HandleResolver.setupSessionWithServer(HandleResolver.java:2039)
	at net.handle.hdllib.HandleResolver.sendRequestToServerByProtocol(HandleResolver.java:1883)
	... 17 common frames omitted

  - [ ] T143: in config/view screen: delete of (existing) Key-Value tim:hasRow >> blank screen
 

  B010: Ingforms
  - [.] T104: Be able to browse from one dataset to another
  

#EMLO (Oxford); consisting of three large chunks EMpeople, EMplaces, EMdates + some generic work
    
  B012: EMpeople; A configured dataset in timbuctoo for people data

  B013: EMplaces; A configured dataset in timbuctoo for place data
      - [-] EmPeripleoApi; implement the peripleo API to provide data from the Timbuctoo instance; Oxford has to make decision
      - [ ] T142: export as LPIF format (https://github.com/LinkedPasts/linked-places); record based OR/AND via API?
    
  B014: EMdates; webapi + app for converting dates that uses data from EM collections in Timbuctoo; 1st version built by Hayco
      - [ ] integrate into EMplaces

 - [ ] EmAuth (2018-04-04)
	Allow login integration with their systems 
 ~ [ ] EmBugreports
      Handling data bugreports or data submissions



# data import
  - [.] T125: toevoegen (extra) data aan anansi/2TB: 
   https://mutations.nodegoat.ugent.be/.well-known/resourcesync/TIC2/capabilitylist.xml

# Technical debt 
  - [.] T114: Refactor ImportStatus and EntryImportStatus (remove extraneous information from ImportStatus).
  
  B009: Timbuctoo stabieler maken
    ~ [ ] T093: Bij een union type worden alleen de velden van het eerste type getoond in het 'Facet configuration screen'
    ~ [ ] T094: Zorgen dat de indexer goede foutmeldingen geeft en om kan gaan met http foutcodes
          - Foutcodes van Timbuctoo (b.v. niet meer ingelogd)
          - Foutcodes van Elastic search (b.v. too many requests)
    ~ [X] T095: SummaryProps als een entity meerdere types heeft kan de verkeerde summary prop worden opgehaald.
    ~ [ ] T096: Databases sluiten af en toe na mappen
          1. import excel
          2. execute mapping
          3. Vraag data op via front-end (geeft de foutmelding)
  - [X] T054: configuratie van links naar buiten toe (e.g. geonames, url met afbeelding, obituary url)
  - [X] T100: IntegratieTests falen als, de build van Timbuctoo te langzaam is
        Dit gebeurd nu vooral op Dockerhub. Leuke bijvangst is dat we nu betere statusmessages kunnen tonen tijdens een import
  - [ ] T111: JsonLd staat iri's toe met escape characters bijvoorbeeld: http://resources.huygens.knaw.nl/ingforms/atlantischewereld\\wetgeving. Deze worden echter aangepast door Rdf4J naar http://resources.huygens.knaw.nl/ingforms/atlantischewereld\wetgeving. Dit geeft problemen bij het aanmaken van het GraphQl schema. Hiervoor is een fix gemaakt. Het echte probleem, dat de uri's anders zijn dan het origineel, is hier nog niet mee opgelost.
    
    B007: resourceSync (v2.0)
    Make our resourcesync exchange protocol use changelists

    - [X] T053: Update ResourceSync spec to allow for separate changelist
    - [X] T040: Update ResourceSync import code to allow for separate changelist (also check if update works)
    - [X] T042: Update ResourceSync generation code to provide a Changelist next to the resourcelist
    - [X] T044: resourcesync update kunnen triggeren via graphql (dat betekent dat we per dataset moeten gaan bijhouden welke bron rs-url die had)
          a graphql mutation for launching a resourcesync
          a graphql mutation for triggering an update of a resourcesync dataset
    - [>T044] T088: resourcesync API via graphQL exposen (list data from url and import dataset)
    - [X] T043: make the resourcesync client able to import password protected resources
    - [ ] T107: store the original graph in the TruePatchStore
  B006: rdf_upload (v2.0)
    Allow a user to do an upload throught the GUI

    - [X] T035: "Create dataset" optie aanmaken in GUI
    - [X] T037: Upload web interface in de GUI voor rdf data
    ~ [ ] T101: Upload status teruggeven (hoe ver timbuctoo is met uploaden)
    - [ ] T039: andere gebruikers als editor/admin kunnen toevoegen aan je dataset (graphiql)
  B010: Work out how temporal features can be used while querying @EmPlaces @Humigec
        - [ ] T103: How can we model and query which people lived in the same city at the same time
    - [ ] T104: How can we model and query that a query affects a certain time period (give me all people who where a married goldsmith between 1580 and 1620)
  B011: Be able to return results on a map @EmPlaces
    - [X] T106: How can elasticsearch return a limited amount of buckets for all results in geographic sections of roughly equal geographical size
          https://i.stack.imgur.com/f0T0x.png
          https://developers.google.com/maps/documentation/maps-static/intro
# later
  - [ ] T135: Type van value type teruggeven in het schema
  - [ ] T133: Migrate Timbuctoo to Java 11. (September 2018, max December 2018)
  - [ ] T126: Make it possible to import data from multiple resourcesync sources (Merge datasets)
  - [ ] T127: Elasticsearch 6.3.0 complains about multiple types with the indexing of 2TBI
          We now use elasticsearch 5.6.5, so we only run into problems when updating it.
  - [ ] T128: Refactor ResourceSync code to have only one set of DTOs (currently two in "xml" and "download")
    - [ ] T122: Make it possible to create handles (permanent URI's for entities). @EmPlaces
    - [ ] T119: import+map 'bron'-files of BioPort (xls, already in SURFdrive; needs some thinking on mapping/showing them in dataset)
    - [ ] T116: RDF-dump of WomenWriters, for deposit at DANS.
        NOTE van Jauco: Uit de mail herinner ik me dat we json zouden doen, geen RDF. Gaan we toch RDF doen? (vind ik prima, maar dan moeten we zorgen dat de versie historie ook naar PROV-O mapped)
    - [ ] T117: import+map dataset 'Leidse studenten tussen 1575 en 1812' (is MS access database)
  B005: tabular upload (v3.0)
    Ge-uploade tabulaire data onder een voorspelbare graphql endpoint plaatsen en niet in het overzicht van collecties tonen

    ~ [ ] T102: Upload status teruggeven (hoe ver timbuctoo is met uploaden) zodat je een progress bar kan weergeven
    - [ ] T031: Ge-uploade tabulaire data onder een voorspelbare graphql endpoint plaatsen + excel data niet in het overzicht van collecties tonen
    - [ ] T034: graphql mutation voor applyen van jsonnet mapping die als resultaat de evt. mapping errors teruggeeft (die nu in de js gechecked worden)
    - [ ] T036: Upload web interface in de GUI voor csv data
    - [ ] T038: GUI voor het uploaden van een jsonnet & json-ld mapping (misschien wel met codemirror voor het typen ervan) + iets dat de mapping aan de juiste csv file bindt
  ~ [ ] T092: Implementeer boolean facet. (Lodewijk wilde bij 2TBI personen kunnen zien welke personen een connectie hadden met BioPort personen)
  B004: overdracht jauco
    - [ ] T063: overdracht beheerservices Timbuctoo instantie -- password etc.
    - [ ] T066: overdracht GUI 
  T099: GUI polish
    - [ ] T091: add default fulltext config based on the view config
    - [ ] T051: sortering van results? alfabetisch mogelijk? sortering op meerdere velden?
    - [ ] T115: resultatenlijst geeft 'context' van zoekterm weer
    - [ ] T052: Remove hsid from frontend URI (aka: fix major security leak)
    - [ ] T055: order of facet blocks in view is not the same as configured
    - [ ] T056: possibility to position diffent fields in screen view on horizontal axis (so it seems to be a 'string')
    - [ ] T060: count o.i.d. op previous-next cursors zodat je weet waar je bent
    - [ ] T070: remove ':' after field label in screen view
    - [ ] T071: from record view a 'back button' to list of results
    - [ ] T078: mee scrollen van facet menubalk bij lange resultaten lijst
    - [ ] T081: view screen config: ingevoerde label zichtbaar (vgl. facet config)
    - [ ] T118: do not show edit screen/facet functionality to users who don't have the permissions to do this
  - [ ] T057: data-issues in DWC: 
        - year '4242'
        - gender caps
        - source dataset missing
        - <html> tags
  - [-] T058: k8s scripts bugs bekijken
  - [ ] T062: mapping: generate provenance
  - [ ] T064: elasticsearch indexen backoff if error
  - [ ] T065: direct indexeren na upload gaat niet goed --> trigger te vroeg
  - [ ] T067: test server with db backups
  - [ ] T068: search in all datasets
  - [ ] T072: re-ordering (and selection) of collection blocks/rectangles in dataset view 
  ~ [ ] T074: herstructureren dataset + stores
  ~ [ ] T075: requestlogging GoReplay
  - [ ] T076: add a mutation to mark a dataset as promoted in graphQL --> testen op DWC op data.huygens
  - [ ] T077: persistent IDs (handle) voor entiteiten
        Dat iedere nieuwe subject ook een predicate krijgt met daarin de url (als xsd:anyURI) van de PID-generator die dan
        weer doorverwijst naar het item in de timbuctoo GUI. Het migreren van de PIDS als de config van timbuctoo wordt
        aangepast valt buiten deze issue
  ~ [ ] T080: 1 clock voor Timbuctoo
  - [ ] T082: problemen met ':' in ID-veld van csv na mapping --> dubbele uri encoding FE
  - [ ] T083: verkorte URLs voor dataset namen
  - [ ] T085: JsonLD edit endpoint naar nieuwe generate log (dataset overzetten) --> herstartbaar na reboot
  ~ [ ] T086: dataset name toevoegen logging import
  - [ ] T087: gegenereerde metadata moet content van provenance ook meegeven 
  - [ ] T089: volgorde van naamselementen in resultaten lijst (bv. "Pieter Winter van jonkheer" moet zijn "jonkheer Pieter van Winter")
  - [ ] T090: aantal personen in DWC in Anansi is de helft van aantal personen DWC in data.huygens 
  ~ [ ] T098: Move over to bazel
        The bazel compiler is significantly faster and enforces a proper separation of packages and explicit dependencies
        Currently we can run bazel just fine, however it might not run correctly during a docker build (we'd need to 
        check that) and it is broken because commits often introduce new dependency usages. This task would mean to stop 
        using maven as the default build and instead start using bazel on our pc's and on the CI build. We'd still keep the 
        pom files and would still allow maven builds
  - [ ] T109: volgorde van data behouden/modellen, bijv. lijst van auteurs bij een publicatie @Rutger
  - [ ] T110: Core Trust Seal (fka Data Seal of Approval) for data.huygens and anansi.clariah

# projects

  Anansi ("Gertjan Filarski" <gertjan.filarski@huygens.knaw.nl>)
    - [X] CL_RdfIngest (2018-12-31)
      We adapt timbuctoo to allow for RDF ingests and map the RDF to a graphql schema that allows for path walking.

      And some other ingelogd

          > This task will deliver a linked data store with a RESTful API for basic CRUD operations. 
          > Given that scalability and performance are considered crucial a native RDF-triple store is an unlikely option. 
          > In this task both a document database – like MongoDB - storing JSON-LD is considered and a solution designed around more generalized structures like a graph store – e.g. Neo4J – with RDF/JSON-LD exposure.
          > 
          > The store will be accessible through (1) a REST API implemented in JAVA mapping JAVA entities to graph resources; 
          > and (2) through various search API‘s. 
          > A native query language: an RDF-triple store will offer built-in SPARQL while a generalized graph database like Neo4J offers e.g. the CYPHER query language. 
          > 
          > [...]
          > 
          > Budget: € 416.443,68 [=Also the budget for CL_ElasticsearchFilter]
            -- CLARIAH TP - v1.0.pdf p.14

    - [ ] Cl_ElasticsearchFilter (2018-12-31)
      We index the RDF in elasticsearch and allow filtering of the graphql results through that index.
          
          > Besides these native query languages the plan allows for data indexation as a method to improve performance. 
          > Both SOLR and/or ElasticSearch are considered as alternative search engines.
          > For front-end access Huygens ING will setup an API to allow implementation of its Faceted Search library.
          > 
          > [...]
          > 
          > Budget: € 416.443,68 [=Also the budget for CL_RdfIngest]
            -- CLARIAH TP - v1.0.pdf p.14

          2018-04-05:
            We planned to index the RDF in elasticsearch and allow filtering of the graphql results through that index.

            However, we encountered probles
          2018-04-05:
            We plan to index the RDF in elasticsearch and allow filtering of the graphql results through that index.
          2018-04-05:
            We plan to index the RDF in elasticsearch and allow filtering of the graphql results through that index.

    - [ ] CL_Rml (2018-12-31)
      A data conversion system through the RML language
          
          > This task will provide automated maintenance tools. 
          > At this moment tools for [...] internal and external linking [...] are considered. 
          > Data provided by WP3, 4 and 5 is considered curated and ready to be included in the data store. 
          > There are no provisions for further manual data curation of the centralized store by a permanent group of editors.
          > 
          > [...]
          > 
          > Budget: € 141.874,-
            -- CLARIAH TP - v1.0.pdf p.15

#Archive/DONE
   - [X] T138: Return 404 when a resourcesync change is requested for an unknown version like 'change99999.nqud' when the last change is 'change2.nqud'
   - [X] T145: (=SANDS-421) onderstaande bericht op homepage van NEWW VRE plaatsen, http://resources.huygens.knaw.nl/womenwriters:

Dear members of the DARIAH-EU Working Group Women Writers in History, and other visitors,
The NEWW VRE is at present being updated and revised by developers at Huygens-ING. From September 21st up to and including October 31 2018 the VRE is only open for consultation (without password). Data entry and editing of records will start again when the ongoing amendments are finalized. }}{{Any questions can be addressed to one of us: Amelia Sanz (amsanz@ucm.es) and Marie Nedregotten Sørbø (mns@hivolda.no) (Chairs of the WWIH Board). Janouk de Groot (janouk.de.groot@huygens.knaw.nl) (DANS-assistant at Huygens-ING)

    - [X] T146: (=SANDS-422) beperk toegang applicatie NEWW VRE tot user janouk.de.groot@huygens.knaw.nl / janouk@gmail.com
    - [X] T108: Demo breekt met upload nieuwe versie Timbuctoo
          Migratie van oude SummaryProps
  B008: 2TBI-demo
    Datasets uploaden, zorgen dat de GUI configurabel genoeg is en eventuele bugs fixen zodat de demo werkt
    - [X] T084: Summaryprops automatisch laten terugvallen op well-known predicates (zoals rdfs:label foaf:depiction etc) (misschien configureerbaar?)
    - [X] T020: 2tbi, RAA en bioport importplannetje waarbij bioport id's alignen
    - [X] T021: timbuctoo schema bug die getriggerd wordt door 2tbi data fixen
    - [X] T022: View configurator aanpassen zodat we links naar andere entities kunnen maken
    - [X] T024: Bioport mapping aanpassen en opnieuw runnen
          subjecturi: http://www.biografischportaal.nl/persoon/{Bioport_id}
          type: bioportperson
          zorgen dat bij de import de rdfPrefix niet op example.org staat maar op de anansi prefix
    - [X] T025: RAA mapping aanpassen en opnieuw runnen
          subject: gewoon een custom uri
          http://www.w3.org/2002/07/owl#sameAs {bprURL}
          type: Ambtsdrager
          viafurl als anyuri
          plus officesheld
          zorgen dat bij de import de rdfPrefix niet op example.org staat maar op de anansi prefix
    - [X] T026: 2TBI via sed aanpassen en importeren
          sameas: {bprURL}
          sed 's|http://schema.org/Person/biografisch_portaal> "\(.*\)"^^<http://schema.org/URL>|http://www.w3.org/2002/07/owl#sameAs> <\1>|'
    - [X] T027: nieuwe timbuctoo releasen
    - [X] T041: graphiql mutation om de descriptie (title, provenance, depiction, colophon, namen van de collecties) aan te passen
    - [X] T023: dataset VOID-description mutation toevoegen
    - [X] T028: werk documentatie bij
          - welke datatypen indexeren we als dates, 
          - hoe kun je checken of je rdf valide is
          - how to add valid describedBy data (must be rdf+xml in VOID)
    - [-] T047: 2TBI is het mogelijk gegevens over projectpartners op te nemen op dataset homepage?
 - [X] T101: Import the GBA data of Amstelveen for Rutger
 - [X] T129: Resourcesync documentation
 - [X] T130: Resourcesync resourcelist expose only dataset.nq
 - [X] T124: herindexeren WomenWriters @SANDS-320
          De Viitanen-records zijn gewijzigd maar verschijnen nog als zoekresultaat
          Het probleem is een corrupte database. Timbuctoo geeft twee keer de verkeerde Viitanen (http://resources.huygens.knaw.nl    /womenwriters/vre/persons/4443aaac-76bc-4484-97ed-36a637957469) terug. De eerste keer is het de juiste versie. De tweede keer is het een oudere versie uit september 2017. -- We kunnen het probleem fixen door een wijziging te doen in de graafdatabase. We kunnen ook Women Writers converteren naar rdf en hem verder laten werken met de nieuwe Timbuctoo
 - [X] T113: Indexeren private datasets gaat niet goed op data.huygens.knaw.nl
          Code aangepast, moet getest worden met een release.
 - [X] T123: Asynchroon rdf uploaden lijkt problemen tegeven bij updaten van index.
          De trigger wordt te vroeg uitgevoerd
          Dit zou best wel eens hetzelfde probleem als T113. 
          Als de gebruiker (indexer is ook een Timbuctoo gebruiker) geen rechten heeft op een dataset lijkt het alsof de dataset nog niet bestaat. Deze issue opnieuwe controleren na release van Timbuctoo.
 - [X] T151: update Jackson
 - [X] T147: Users, Roles, Permissions >> write design document
 - [X] T105: Read up on the EMPlaces data model
          https://github.com/culturesofknowledge/emplaces/
 - [X] T102: Test ingforms scripts
 - [X] T045: Migratiegids in data.huygens
 - [X] T131: test-import https://github.com/culturesofknowledge/emplaces/blob/master/src/coredataextractor/Opole_extracted_data.ttl
 - [-] T132: assess whether the two xlsx-files in EM-PPD/Places/Silesia_sample_data are propperly structured (enough) to import into Timbuctoo @EMLO
 - [X] T137: Reimport Opele dataset
	When the discussion is completed on https://github.com/culturesofknowledge/emplaces/issues/26
 - [X] T097: Schema bugs fixen en betere testcases maken
 - [X] T136: EMtinyurl / alternative to handle-service
      Generate short, persistent, somewhat readable uri's for citation of entities
          
          > - they refer to entries. Not search results
          > - We could implement it as a URI shortener
          > - we should handle the case where two entries are merged
          > - These are the public uri's that redirect you to the view details page of the entity








