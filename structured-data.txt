//current max task number: T132

# New
  - [ ] T126: Make it possible to import data from multiple resourcesync sources
  - [ ] T127: Elasticsearch 6.3.0 complains about multiple types with the indexing of 2TBI
          We now use elasticsearch 5.6.5, so we only run into problems when updating it.
  - [ ] T128: Refactor ResourceSync code to have only one set of DTOs (currently two in "xml" and "download")
  - [ ] T131: test-import https://github.com/culturesofknowledge/emplaces/blob/master/src/coredataextractor/Opole_extracted_data.ttl @EMLO
  - [ ] T132: assess whether the two xlsx-files in EM-PPD/Places/Silesia_sample_data are propperly structured (enough) to import into Timbuctoo @EMLO
  
# Production blockers
  
# Production bugs
  - [ ] T113: Indexeren private datasets gaat niet goed op data.huygens.knaw.nl
          Code aangepast, moet getest worden met een release.
  - [ ] T124: herindexeren WomenWriters @SANDS-320
          De Viitanen-records zijn gewijzigd maar verschijnen nog als zoekresultaat
          Het probleem is een corrupte database. Timbuctoo geeft twee keer de verkeerde Viitanen (http://resources.huygens.knaw.nl    /womenwriters/vre/persons/4443aaac-76bc-4484-97ed-36a637957469) terug. De eerste keer is het de juiste versie. De tweede keer is het een oudere versie uit september 2017.

          We kunnen het probleem fixen door een wijziging te doen in de graafdatabase. We kunnen ook Women Writers converteren naar rdf en hem verder laten werken met de nieuwe Timbuctoo.
  - [ ] T120: Detail view van importstatus heeft een bug
        - In eerste instantie 8 importers, later 2 met exact dezelfde informatie.
  - [ ] T121: Importer heeft een bug. Ik was twee datasets tegelijk aan het uploaden en paste toen de naam van de eerste dataset aan. Dan zie je twee imports lopen (van beide datasets 1) toen de tweede import klaar was ging de 2e log van de eerste dataset ook al importeren. Voordat de eerste log dus klaar was. 
  - [>T096] T030: Database sluit na upload en mapping
  - [>T097] T029: Schema geeft meer properties in metadata terug, dan die beschikbaar zijn (owl:sameAs bioport person, het ophalen van unknown via sameAs)
  - [X] T123: Asynchroon rdf uploaden lijkt problemen tegeven bij updaten van index.
          De trigger wordt te vroeg uitgevoerd
          Dit zou best wel eens hetzelfde probleem als T113. 
          Als de gebruiker (indexer is ook een Timbuctoo gebruiker) geen rechten heeft op een dataset lijkt het alsof de dataset nog niet bestaat. Deze issue opnieuwe controleren na release van Timbuctoo.

  B010: Ingforms
    - [.] T102: Test ingforms scripts

- [.] T104: Be able to browse from one dataset to another
- [ ] T045: Migratiegids in data.huygens
  

# data import
- [ ] T125: toevoegen (extra) data aan anansi/2TB: 
   https://mutations.nodegoat.ugent.be/.well-known/resourcesync/TIC2/capabilitylist.xml

# Technical debt 
  - [ ] T114: Refactor ImportStatus and EntryImportStatus (remove extraneous information from ImportStatus).
  
  B009: Timbuctoo stabieler maken
    - [X] T097: Schema bugs fixen en betere testcases maken
    ~ [ ] T093: Bij een union type worden alleen de velden van het eerste type getoond in het 'Facet configuration screen'
    ~ [ ] T094: Zorgen dat de indexer goede foutmeldingen geeft en om kan gaan met http foutcodes
          - Foutcodes van Timbuctoo (b.v. niet meer ingelogd)
          - Foutcodes van Elastic search (b.v. too many requests)
    ~ [X] T095: SummaryProps als een entity meerdere types heeft kan de verkeerde summary prop worden opgehaald.
    ~ [ ] T096: Databases sluiten af en toe na mappen
          1. import excel
          2. execute mapping
          3. Vraag data op via front-end (geeft de foutmelding)
  - [X] T054: configuratie van links naar buiten toe (e.g. geonames, url met afbeelding, obituary url)
  - [X] T100: IntegratieTests falen als, de build van Timbuctoo te langzaam is
        Dit gebeurd nu vooral op Dockerhub. Leuke bijvangst is dat we nu betere statusmessages kunnen tonen tijdens een import
  - [ ] T111: JsonLd staat iri's toe met escape characters bijvoorbeeld: http://resources.huygens.knaw.nl/ingforms/atlantischewereld\\wetgeving. Deze worden echter aangepast door Rdf4J naar http://resources.huygens.knaw.nl/ingforms/atlantischewereld\wetgeving. Dit geeft problemen bij het aanmaken van het GraphQl schema. Hiervoor is een fix gemaakt. Het echte probleem, dat de uri's anders zijn dan het origineel, is hier nog niet mee opgelost.
    B007: resourceSync (v2.0)
    Make our resourcesync exchange protocol use changelists

    - [X] T053: Update ResourceSync spec to allow for separate changelist
    - [X] T040: Update ResourceSync import code to allow for separate changelist (also check if update works)
    - [.] T042: Update ResourceSync generation code to provide a Changelist next to the resourcelist
    - [ ] T044: resourcesync update kunnen triggeren via graphql (dat betekent dat we per dataset moeten gaan bijhouden welke bron rs-url die had)
          a graphql mutation for launching a resourcesync
          a graphql mutation for triggering an update of a resourcesync dataset
    - [>T044] T088: resourcesync API via graphQL exposen (list data from url and import dataset)
    - [.] T043: make the resourcesync client able to import password protected resources
    - [ ] T107: store the original graph in the TruePatchStore
  B006: rdf_upload (v2.0)
    Allow a user to do an upload throught the GUI

    - [X] T035: "Create dataset" optie aanmaken in GUI
    - [X] T037: Upload web interface in de GUI voor rdf data
    ~ [ ] T101: Upload status teruggeven (hoe ver timbuctoo is met uploaden)
    - [ ] T039: andere gebruikers als editor/admin kunnen toevoegen aan je dataset (graphiql)
  B010: Work out how temporal features can be used while querying @EmPlaces @Humigec
    - [.] T105: Read up on the EMPlaces data model
          https://github.com/culturesofknowledge/emplaces/
    - [ ] T103: How can we model and query which people lived in the same city at the same time
    - [ ] T104: How can we model and query that a query affects a certain time period (give me all people who where a married goldsmith between 1580 and 1620)
  B011: Be able to return results on a map @EmPlaces
    - [X] T106: How can elasticsearch return a limited amount of buckets for all results in geographic sections of roughly equal geographical size
          https://i.stack.imgur.com/f0T0x.png
          https://developers.google.com/maps/documentation/maps-static/intro
# later
    - [ ] T122: Make it possible to create handles (permanent URI's for entities). @EmPlaces
    - [ ] T119: import+map 'bron'-files of BioPort (xls, already in SURFdrive; needs some thinking on mapping/showing them in dataset)
    - [ ] T116: RDF-dump of WomenWriters, for deposit at DANS.
        NOTE van Jauco: Uit de mail herinner ik me dat we json zouden doen, geen RDF. Gaan we toch RDF doen? (vind ik prima, maar dan moeten we zorgen dat de versie historie ook naar PROV-O mapped)
    - [ ] T117: import+map dataset 'Leidse studenten tussen 1575 en 1812' (is MS access database)
  B005: tabular upload (v3.0)
    Ge-uploade tabulaire data onder een voorspelbare graphql endpoint plaatsen en niet in het overzicht van collecties tonen

    ~ [ ] T102: Upload status teruggeven (hoe ver timbuctoo is met uploaden) zodat je een progress bar kan weergeven
    - [ ] T031: Ge-uploade tabulaire data onder een voorspelbare graphql endpoint plaatsen + excel data niet in het overzicht van collecties tonen
    - [ ] T034: graphql mutation voor applyen van jsonnet mapping die als resultaat de evt. mapping errors teruggeeft (die nu in de js gechecked worden)
    - [ ] T036: Upload web interface in de GUI voor csv data
    - [ ] T038: GUI voor het uploaden van een jsonnet & json-ld mapping (misschien wel met codemirror voor het typen ervan) + iets dat de mapping aan de juiste csv file bindt
  ~ [ ] T092: Implementeer boolean facet. (Lodewijk wilde bij 2TBI personen kunnen zien welke personen een connectie hadden met BioPort personen)
  B004: overdracht jauco
    - [ ] T063: overdracht beheerservices Timbuctoo instantie -- password etc.
    - [ ] T066: overdracht GUI 
  T099: GUI polish
    - [ ] T091: add default fulltext config based on the view config
    - [ ] T051: sortering van results? alfabetisch mogelijk? sortering op meerdere velden?
    - [ ] T115: resultatenlijst geeft 'context' van zoekterm weer
    - [ ] T052: Remove hsid from frontend URI (aka: fix major security leak)
    - [ ] T055: order of facet blocks in view is not the same as configured
    - [ ] T056: possibility to position diffent fields in screen view on horizontal axis (so it seems to be a 'string')
    - [ ] T060: count o.i.d. op previous-next cursors zodat je weet waar je bent
    - [ ] T070: remove ':' after field label in screen view
    - [ ] T071: from record view a 'back button' to list of results
    - [ ] T078: mee scrollen van facet menubalk bij lange resultaten lijst
    - [ ] T081: view screen config: ingevoerde label zichtbaar (vgl. facet config)
    - [ ] T118: do not show edit screen/facet functionality to users who don't have the permissions to do this
  - [ ] T057: data-issues in DWC: 
        - year '4242'
        - gender caps
        - source dataset missing
        - <html> tags
  - [-] T058: k8s scripts bugs bekijken
  - [ ] T062: mapping: generate provenance
  - [ ] T064: elasticsearch indexen backoff if error
  - [ ] T065: direct indexeren na upload gaat niet goed --> trigger te vroeg
  - [ ] T067: test server with db backups
  - [ ] T068: search in all datasets
  - [ ] T072: re-ordering (and selection) of collection blocks/rectangles in dataset view 
  ~ [ ] T074: herstructureren dataset + stores
  ~ [ ] T075: requestlogging GoReplay
  - [ ] T076: add a mutation to mark a dataset as promoted in graphQL --> testen op DWC op data.huygens
  - [ ] T077: persistent IDs (handle) voor entiteiten
        Dat iedere nieuwe subject ook een predicate krijgt met daarin de url (als xsd:anyURI) van de PID-generator die dan
        weer doorverwijst naar het item in de timbuctoo GUI. Het migreren van de PIDS als de config van timbuctoo wordt
        aangepast valt buiten deze issue
  ~ [ ] T080: 1 clock voor Timbuctoo
  - [ ] T082: problemen met ':' in ID-veld van csv na mapping --> dubbele uri encoding FE
  - [ ] T083: verkorte URLs voor dataset namen
  - [ ] T085: JsonLD edit endpoint naar nieuwe generate log (dataset overzetten) --> herstartbaar na reboot
  ~ [ ] T086: dataset name toevoegen logging import
  - [ ] T087: gegenereerde metadata moet content van provenance ook meegeven 
  - [ ] T089: volgorde van naamselementen in resultaten lijst (bv. "Pieter Winter van jonkheer" moet zijn "jonkheer Pieter van Winter")
  - [ ] T090: aantal personen in DWC in Anansi is de helft van aantal personen DWC in data.huygens 
  ~ [ ] T098: Move over to bazel
        The bazel compiler is significantly faster and enforces a proper separation of packages and explicit dependencies
        Currently we can run bazel just fine, however it might not run correctly during a docker build (we'd need to 
        check that) and it is broken because commits often introduce new dependency usages. This task would mean to stop 
        using maven as the default build and instead start using bazel on our pc's and on the CI build. We'd still keep the 
        pom files and would still allow maven builds
  - [ ] T109: volgorde van data behouden/modellen, bijv. lijst van auteurs bij een publicatie @Rutger
  - [ ] T110: Core Trust Seal (fka Data Seal of Approval) for data.huygens and anansi.clariah
# projects
  Emlo ("Arno Bosse" <arno.bosse@oxford.edu.uk>)
    - [ ] EmAuth (2018-04-04)
      Allow login integration with their systems

    - [ ] EmDates
      A webapi + app for converting dates that uses data from EM collections in timbuctoo

    - [ ] EmPlaces
      A configured dataset in timbuctoo for place data

    - [ ] EmPeople
      A configured dataset in timbuctoo for people data

    - [ ] EmPeripleoApi
      Implement the peripleo API to provide data from the timbuctoo instance

    - [ ] EmBugreports
      Handling data bugreports or data submissions

    - [ ] EmTinyurl
      Generate short, persistent, somewhat readable uri's for citation of entities
          
          > - they refer to entries. Not search results
          > - We could implement it as a URI shortener
          > - we should handle the case where two entries are merged
          > - These are the public uri's that redirect you to the view details page of the entity
            -- https://trello.com/c/jfR5PMmk/76

  Anansi ("Gertjan Filarski" <gertjan.filarski@huygens.knaw.nl>)
    - [ ] CL_RdfIngest (2018-12-31)
      We adapt timbuctoo to allow for RDF ingests and map the RDF to a graphql schema that allows for path walking.

      And some other ingelogd

          > This task will deliver a linked data store with a RESTful API for basic CRUD operations. 
          > Given that scalability and performance are considered crucial a native RDF-triple store is an unlikely option. 
          > In this task both a document database – like MongoDB - storing JSON-LD is considered and a solution designed around more generalized structures like a graph store – e.g. Neo4J – with RDF/JSON-LD exposure.
          > 
          > The store will be accessible through (1) a REST API implemented in JAVA mapping JAVA entities to graph resources; 
          > and (2) through various search API‘s. 
          > A native query language: an RDF-triple store will offer built-in SPARQL while a generalized graph database like Neo4J offers e.g. the CYPHER query language. 
          > 
          > [...]
          > 
          > Budget: € 416.443,68 [=Also the budget for CL_ElasticsearchFilter]
            -- CLARIAH TP - v1.0.pdf p.14

    - [ ] Cl_ElasticsearchFilter (2018-12-31)
      We index the RDF in elasticsearch and allow filtering of the graphql results through that index.
          
          > Besides these native query languages the plan allows for data indexation as a method to improve performance. 
          > Both SOLR and/or ElasticSearch are considered as alternative search engines.
          > For front-end access Huygens ING will setup an API to allow implementation of its Faceted Search library.
          > 
          > [...]
          > 
          > Budget: € 416.443,68 [=Also the budget for CL_RdfIngest]
            -- CLARIAH TP - v1.0.pdf p.14

          2018-04-05:
            We planned to index the RDF in elasticsearch and allow filtering of the graphql results through that index.

            However, we encountered probles
          2018-04-05:
            We plan to index the RDF in elasticsearch and allow filtering of the graphql results through that index.
          2018-04-05:
            We plan to index the RDF in elasticsearch and allow filtering of the graphql results through that index.

    - [ ] CL_Rml (2018-12-31)
      A data conversion system through the RML language
          
          > This task will provide automated maintenance tools. 
          > At this moment tools for [...] internal and external linking [...] are considered. 
          > Data provided by WP3, 4 and 5 is considered curated and ready to be included in the data store. 
          > There are no provisions for further manual data curation of the centralized store by a permanent group of editors.
          > 
          > [...]
          > 
          > Budget: € 141.874,-
            -- CLARIAH TP - v1.0.pdf p.15

#Archief
  - [X] T108: Demo breekt met upload nieuwe versie Timbuctoo
          Migratie van oude SummaryProps
  B008: 2TBI-demo
    Datasets uploaden, zorgen dat de GUI configurabel genoeg is en eventuele bugs fixen zodat de demo werkt
    - [X] T084: Summaryprops automatisch laten terugvallen op well-known predicates (zoals rdfs:label foaf:depiction etc) (misschien configureerbaar?)
    - [X] T020: 2tbi, RAA en bioport importplannetje waarbij bioport id's alignen
    - [X] T021: timbuctoo schema bug die getriggerd wordt door 2tbi data fixen
    - [X] T022: View configurator aanpassen zodat we links naar andere entities kunnen maken
    - [X] T024: Bioport mapping aanpassen en opnieuw runnen
          subjecturi: http://www.biografischportaal.nl/persoon/{Bioport_id}
          type: bioportperson
          zorgen dat bij de import de rdfPrefix niet op example.org staat maar op de anansi prefix
    - [X] T025: RAA mapping aanpassen en opnieuw runnen
          subject: gewoon een custom uri
          http://www.w3.org/2002/07/owl#sameAs {bprURL}
          type: Ambtsdrager
          viafurl als anyuri
          plus officesheld
          zorgen dat bij de import de rdfPrefix niet op example.org staat maar op de anansi prefix
    - [X] T026: 2TBI via sed aanpassen en importeren
          sameas: {bprURL}
          sed 's|http://schema.org/Person/biografisch_portaal> "\(.*\)"^^<http://schema.org/URL>|http://www.w3.org/2002/07/owl#sameAs> <\1>|'
    - [X] T027: nieuwe timbuctoo releasen
    - [X] T041: graphiql mutation om de descriptie (title, provenance, depiction, colophon, namen van de collecties) aan te passen
    - [X] T023: dataset VOID-description mutation toevoegen
    - [X] T028: werk documentatie bij
          - welke datatypen indexeren we als dates, 
          - hoe kun je checken of je rdf valide is
          - how to add valid describedBy data (must be rdf+xml in VOID)
    - [-] T047: 2TBI is het mogelijk gegevens over projectpartners op te nemen op dataset homepage?
 - [X] T101: Import the GBA data of Amstelveen for Rutger
 - [X] T129: Resourcesync documentation
 - [X] T130: Resourcesync resourcelist expose only dataset.nq

